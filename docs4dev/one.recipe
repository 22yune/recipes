#!/usr/bin/env python
### -#*- coding:gbk -*-

from calibre.web.feeds.recipes import BasicNewsRecipe # 引入 Recipe 基础类
import mechanize

def prn_obj(obj):
    print '\n'.join(['%s:%s' % item for item in obj.__dict__.items()])

class Docs4dev(BasicNewsRecipe): # 继承 BasicNewsRecipe 类的新类名

    #///////////////////
    # 设置电子书元数据
    #///////////////////
    #title = 'Spring中文文档' # 电子书名
    #description = 'Spring中文文档' # 电子书简介
    #cover_url = '' # 电子书封面
    #masthead_url = '' # 页头图片
    __author__ = 'docs4dev' # 作者
    language = 'zh' # 语言
    #encoding = 'GBK' # 编码

    #///////////////////
    # 抓取页面内容设置
    #///////////////////
    #keep_only_tags = [{ 'class': 'example' }] # 仅保留指定选择器包含的内容
    #no_stylesheets = True # 去除 CSS 样式
    #remove_javascript = True # 去除 JavaScript 脚本
    auto_cleanup = True # 自动清理 HTML 代码
    delay = 5 # 抓取页面间隔秒数
    max_articles_per_feed = 999 # 抓取文章数量


    def get_browser(self):
        username = ''
        password = ''
        print('loging....brower====')
        br = BasicNewsRecipe.get_browser(self)
        #options
        br.set_handle_equiv(True)
        br.set_handle_gzip(True)
        br.set_handle_redirect(True)
        br.set_handle_referer(True)
        br.set_handle_robots(False)

        #Follows refresh 0 but not hangs on refresh > 0
        br.set_handle_refresh(mechanize._http.HTTPRefreshProcessor(), max_time=1)

        '''
        #debugging?
        br.set_debug_http(True)
        br.set_debug_redirects(True)
        br.set_debug_responses(True)
        '''
        #User-Agent 模拟浏览器行为
        br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]

        if username is not None and password is not None:
            br.open('https://www.docs4dev.com/login')
            #print br.select_form(nr=0)

            #prn_obj(br.forms()[0]._forms[0])
            prn_obj(br.forms()[0] )
            prn_obj(br.forms()[0].controls[3])
            #print(br.forms()[0].controls)
            br.forms()[0].controls[0] = username
            br.forms()[0].controls[1] = password
            #br.submit()
            #print(br.forms()[0]._forms[0])
            req = mechanize.Request('https://www.docs4dev.com/api/auth/login',headers = {
                #'host': 'www.docs4dev.com',
                #'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:69.0) Gecko/20100101 Firefox/69.0',
                'Accept': 'application/json',
                #'Accept-Language': 'zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2',
                'Content-Type': 'application/json',
                #'Accept-Encoding': 'gzip, deflate, br',
                #'Referer': 'https://www.docs4dev.com/login',
                #'X-DOCS4DEV-LANG': 'en',
                #'Cookie': 'locale=zh_CN',
                #'Origin': 'https://www.docs4dev.com',
                #'Connection': 'keep-alive',
                #'Pragma': 'no-cache',
                #'Cache-Control': 'no-cache'
            },method='post')
            #req.host = 'www.docs4dev.com'
            req.add_data('{"username":"674643665@qq.com","password":"12345678"}')
            prn_obj(req)
            #mechanize.urlopen(req)
            #request2 = br.forms()[0].click()
            #print(request2)
            #br.open( req)
            print 'login.....'
        #br.set_cookie('locale=zh_CN; SESSION=OTI1ZjMzZGYtODU4NC00MzlmLTg1ZDUtZjI3NjJjYzU5NWNj')
        br.set_cookie('SESSION','OTI1ZjMzZGYtODU4NC00MzlmLTg1ZDUtZjI3NjJjYzU5NWNj','')
        return br

    #///////////////////
    # 页面内容解析方法
    #///////////////////
    
    def parse_index(self):
        indexs = ['/docs/zh/spring-framework/5.1.3.RELEASE/reference','/docs/zh/java/java8/tutorials']
        ans = [] # 组成最终的数据结构
        for index in indexs :
            doc = self.parse_doc(index)
            ans.append(doc)
        return [('ones',[{'title': 'one' , 'url':'https://www.docs4dev.com/docs/zh/spring-framework/4.3.21.RELEASE/reference/overview-getting-started-with-spring.html'}])] # 返回可供 Calibre 转换的数据结构
        
    def parse_doc(self,index):
        site = 'https://www.docs4dev.com' # 页面列表页
        #index = '/docs/zh/spring-framework/5.1.3.RELEASE/reference'
        soup = self.index_to_soup(site + index) # 解析列表页返回 BeautifulSoup 对象
        doctitle = soup.title.string
        print '==='
        print soup.findAll(name="description")
        print '==='
        #self.description = soup.findAll(name="description")['content']
        links = soup.findAll("li",{"class":"level1"}) # 获取所有文章链接
        articles = [] # 定义空文章资源数组
        for link in links: # 循环处理所有文章链接
            if link.a.get("href") != None :
                title = link.a.contents[0].strip() # 提取文章标题
                url = site + link.a.get("href") # 提取文章链接
                a = {'title': title , 'url':url} # 组合标题和链接
                articles.append(a) # 累加到数组中
        return (doctitle, articles)