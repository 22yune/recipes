#!/usr/bin/env python
### -#*- coding:gbk -*-

from calibre.web.feeds.recipes import BasicNewsRecipe # 引入 Recipe 基础类

class Docs4dev(BasicNewsRecipe): # 继承 BasicNewsRecipe 类的新类名

    #///////////////////
    # 设置电子书元数据
    #///////////////////
    #title = 'Spring中文文档' # 电子书名
    #description = 'Spring中文文档' # 电子书简介
    #cover_url = '' # 电子书封面
    #masthead_url = '' # 页头图片
    __author__ = 'docs4dev' # 作者
    language = 'zh' # 语言
    #encoding = 'GBK' # 编码

    #///////////////////
    # 抓取页面内容设置
    #///////////////////
    #keep_only_tags = [{ 'class': 'example' }] # 仅保留指定选择器包含的内容
    #no_stylesheets = True # 去除 CSS 样式
    #remove_javascript = True # 去除 JavaScript 脚本
    auto_cleanup = True # 自动清理 HTML 代码
    delay = 5 # 抓取页面间隔秒数
    max_articles_per_feed = 999 # 抓取文章数量



    def get_browser(self):
        username = '39669591@qq.com'
        password = 'aizbgo11'
        print('loging....brower====')
        br = BasicNewsRecipe.get_browser(self)
        if username is not None and password is not None:
            br.open('https://www.docs4dev.com/login')
            #print br.select_form(nr=0)
            print  br.select_form(placeholder="邮箱")
            print  br.select_form(id="username")
            print  br.select_form(id="password")
            #br.select_form(name="order")
            #br.form['password'] = password
            #br.form['username']   = username
            br.submit()
            print 'login.....'
        return br

    #///////////////////
    # 页面内容解析方法
    #///////////////////
    
    def parse_index(self):
        indexs = ['/docs/zh/spring-framework/5.1.3.RELEASE/reference','/docs/zh/java/java8/tutorials']
        ans = [] # 组成最终的数据结构
        for index in indexs :
            doc = self.parse_doc(index)
            ans.append(doc)
        return [('ones',[{'title': 'one' , 'url':'https://www.docs4dev.com/docs/zh/spring-framework/4.3.21.RELEASE/reference/overview-getting-started-with-spring.html'}])] # 返回可供 Calibre 转换的数据结构
        
    def parse_doc(self,index):
        site = 'https://www.docs4dev.com' # 页面列表页
        #index = '/docs/zh/spring-framework/5.1.3.RELEASE/reference'
        soup = self.index_to_soup(site + index) # 解析列表页返回 BeautifulSoup 对象
        doctitle = soup.title.string
        print '==='
        print soup.findAll(name="description")
        print '==='
        #self.description = soup.findAll(name="description")['content']
        links = soup.findAll("li",{"class":"level1"}) # 获取所有文章链接
        articles = [] # 定义空文章资源数组
        for link in links: # 循环处理所有文章链接
            if link.a.get("href") != None :
                title = link.a.contents[0].strip() # 提取文章标题
                url = site + link.a.get("href") # 提取文章链接
                a = {'title': title , 'url':url} # 组合标题和链接
                articles.append(a) # 累加到数组中
        return (doctitle, articles)